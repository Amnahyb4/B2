# B2 â€” Data ETL & EDA Pipeline

## ğŸ“Œ Description

**B2** is a Python-based data engineering project that implements a complete **ETL (Extract, Transform, Load)** workflow followed by **Exploratory Data Analysis (EDA)**.

The project:
- Loads raw CSV data
- Cleans and transforms datasets
- Builds analytics-ready Parquet tables
- Generates summary statistics and visualizations
- Saves outputs in a structured and reproducible way

The pipeline is modular, easy to run, and designed for clarity and reproducibility.

---

## âœ¨ Features

- Structured ETL pipeline (load â†’ clean â†’ analytics)
- Parquet-based storage for efficient analytics
- Modular and reusable Python code
- Automated metadata logging
- Exploratory Data Analysis with visualizations
- Fast dependency management using **uv**

---

## ğŸ› ï¸ Setup (Using `uv`)

This project uses **uv** for dependency management and virtual environments.

## Setup (using uv)

### 1. Install uv (if not already installed)
bash
pip install uv

### 2. Create a virtual environment
bash
uv venv


### 3. Activate the virtual environment
bash
source .venv/bin/activate   # macOS / Linux
.venv\Scripts\activate    # Windows


## 4. Install dependencies
bash
uv pip install -r requirements.txt

---

## How to run the ETL

From the project root directory, run:
bash
python scripts/run_etl.py


## How to run the EDA notebook

### 1. Start Jupyter:
bash
jupyter notebook


### 2. Open:
bash
notebooks/eda.ipynb


### 3. Run all cells to reproduce the exploratory analysis using the processed data in data/processed/.


This will:
- Load raw CSV files from data/raw/
- Clean and transform the data
- Join orders with users
- Generate analytics features and flags
- Write processed outputs and run metadata


---

## ğŸ“¦ Outputs

After a successful ETL run, the following files are generated:

### Processed Data
- `data/processed/orders.parquet`
- `data/processed/orders_clean.parquet`
- `data/processed/users.parquet`
- `data/processed/users_clean.parquet`
- `data/processed/analytics_table.parquet`

### Metadata
- `data/processed/_run_meta.json`

### Visualizations
- `reports/figures/*.png`


## ğŸ“‚ Project Structure

```text
B2/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw CSV input files
â”‚   â””â”€â”€ processed/          # Cleaned & analytics Parquet files
â”‚
â”œâ”€â”€ scripts/                # ETL & utility scripts
â”‚   â”œâ”€â”€ run_day1_load.py
â”‚   â”œâ”€â”€ run_day2_clean.py
â”‚   â”œâ”€â”€ run_day3_build_analytics.py
â”‚   â”œâ”€â”€ run_etl.py          # Run full ETL pipeline
â”‚   â””â”€â”€ view_all_parquet.py # Inspect analytics table
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda.ipynb           # Exploratory Data Analysis
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/            # Generated plots (.png)
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data_workflow/      # Reusable pipeline modules
â”‚
â”œâ”€â”€ pyproject.toml          # Project dependencies (uv)
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ .venv/                  # Virtual environment (not committed) '''

---

